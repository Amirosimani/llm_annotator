# LLM Annotators

Large Language Models (LLMs) have opened up exciting possibilities for AI applications that were previously difficult or unattainable. However, evaluating their responses in a systematic way presents real challenges. This project proposes a solution: an ensemble approach where a panel of LLMs act as judges, voting on the accuracy of answers generated by another LLM.

The key is that each LLM performs based on its underlying architecture, training data, and the complexity of the task at hand. To evaluate the result from an LLM for a task such as information extraction from long documents, we can use a domain-agnostic Bayesian model is employed to simultaneously determine the correct answer, the expertise of each LLM judge, and the difficulty level of each question which will surpasses the simple heuristics such as "Majority Vote" method for evaluating answers.

## Classification
* Available models: Gemini, Claude
* Available modality: Text
* Available tasks: Classfication (majority vote, GLAD <sup>1</sup> )





# References
1. [GLAD paper](https://proceedings.neurips.cc/paper_files/paper/2009/file/f899139df5e1059396431415e770c6dd-Paper.pdf) and implementation [referece](https://github.com/notani/python-glad/blob/master/glad.py#L58)
