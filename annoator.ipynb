{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "### NOW:\n",
    "- ~~enforce output format for gemini~~\n",
    "- llama, gpt, ~~claude~~\n",
    "   - send concurrent calls to all models at once\n",
    "- ~~add evaluation if there is a golden set for individual model~~\n",
    "- aggregation strategy\n",
    "   - multiclass classification: \n",
    "      - ~~majority vote~~, add tie breaking strategy\n",
    "      - ~~baysian approach with GT~~\n",
    "      - provide X labeles per class\n",
    "- repeat the same thing for multi-label/ner\n",
    "\n",
    "### LATER:\n",
    "- secret management\n",
    "- ~~update readme~~\n",
    "- add images\n",
    "\n",
    "\n",
    "\n",
    "### nice things to do:\n",
    "- add tqdm to asyncio calls\n",
    "- ~~proper logging~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Annotate\n",
    "from datasets import load_set\n",
    "\n",
    "seed =42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_prompt_template = \"\"\"\n",
    "<data_description>\n",
    "{description}\n",
    "</data_description>\n",
    "-----------\n",
    "\n",
    "<context>\n",
    "{datapoint}\n",
    "</context>\n",
    "------------\n",
    "\n",
    "<labels>\n",
    "{labels}\n",
    "</labels>\n",
    "------------\n",
    "\n",
    "INSTRUCTION:\n",
    "- familirize yourself with the data using data_description\n",
    "- read the context carefully. this is the data point you need to label.\n",
    "- take your time and label the dadatapoint with the most appropriate option using the provided labels.\n",
    "- return the result as a single label from the <labels>. Don't provide explanations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_polarity\", split=\"train\") # https://huggingface.co/datasets/yelp_polarity\n",
    "\n",
    "# take a small sample for dev purposes\n",
    "dataset_sample = dataset.shuffle(seed=seed).select(range(100))\n",
    "\n",
    "# user provided data description\n",
    "DESCRIPTION = \"\"\"\n",
    "This is a dataset for binary sentiment classification.\n",
    "It contains highly polar yelp reviews.\n",
    "Negative polarity is class 0, and positive class 1.\n",
    "\"\"\"\n",
    "\n",
    "LABEL_SET = [0, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [gemini_prompt_template.format(description= DESCRIPTION,\n",
    "                                        datapoint=x,\n",
    "                                        labels=LABEL_SET) for x in dataset_sample[\"text\"][:20]]\n",
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Annotate()\n",
    "\n",
    "VALID_MODELS = [\"gemini\", \"claude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for m in VALID_MODELS:\n",
    "    d[m] = await ann.classification(prompt, model=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/output/20_sample.json\", \"w\") as json_file:\n",
    "    json.dump(d, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results = [d[\"gemini\"], d[\"claude\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = [\"gemini\", \"claude\", \"fake\"]\n",
    "all_results = [[1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = Aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg._get_majority_vote(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg._glad(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = [\"gemini\", \"claude\", \"fake\"]\n",
    "all_results = [[1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Evaluate\n",
    "\n",
    "eval = Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.classification(all_results, strategy=\"majority\", visualize=True, y_labels=y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = [\"gemini\", \"claude\", \"fake\"]\n",
    "all_results = [[1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "               [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]]\n",
    "\n",
    "\n",
    "# list(map(list, zip(*all_results))) \n",
    "# # task, labeler, label\n",
    "# result = [(j, i, sublist[i]) \n",
    "#           for j, sublist in enumerate(all_results) \n",
    "#           for i in range(len(sublist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "THRESHOLD = 1e-5\n",
    "\n",
    "logger = None\n",
    "\n",
    "def Dataset(**kwargs):\n",
    "    \"\"\"Function to create a dataset-like dictionary.\"\"\"\n",
    "    return kwargs\n",
    "\n",
    "def load_data(arr):\n",
    "    data = Dataset(\n",
    "        numLabels=sum(len(sublist) for sublist in arr),\n",
    "        numLabelers=len(arr),\n",
    "        numTasks=len(arr[0]),\n",
    "        numClasses=len(set(arr[0])),\n",
    "        priorZ=np.repeat(1 / len(set(arr[0])), len(set(arr[0]))),\n",
    "        labels=np.array(list(map(list, zip(*arr))))\n",
    "    )\n",
    "\n",
    "    assert np.isclose(data['priorZ'].sum(), 1), 'Incorrect priorZ given'\n",
    "\n",
    "    data['priorAlpha'] = np.ones(data['numLabelers'])\n",
    "    data['priorBeta'] = np.ones(data['numTasks'])\n",
    "    data['probZ'] = np.empty((data['numTasks'], data['numClasses']))\n",
    "    data['beta'] = np.empty(data['numTasks'])\n",
    "    data['alpha'] = np.empty(data['numLabelers'])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def init_logger():\n",
    "    global logger\n",
    "    logger = logging.getLogger('GLAD')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    log_fmt = '%(asctime)s/%(name)s[%(levelname)s]: %(message)s'\n",
    "    logging.basicConfig(format=log_fmt)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def logsigmoid(x):\n",
    "    return - np.logaddexp(0, -x) \n",
    "\n",
    "\n",
    "def EM(data):\n",
    "    data[\"alpha\"] = data[\"priorAlpha\"].copy()\n",
    "    data[\"beta\"] = data[\"priorBeta\"].copy()\n",
    "    data[\"probZ\"][:] = data[\"priorZ\"][:]\n",
    "\n",
    "    print(data[\"probZ\"][:])\n",
    "\n",
    "    EStep(data)\n",
    "    lastQ = computeQ(data)\n",
    "    MStep(data)\n",
    "    Q = computeQ(data)\n",
    "    counter = 1\n",
    "    while abs((Q - lastQ) / lastQ) > THRESHOLD:\n",
    "        if verbose:\n",
    "            logger.info('EM: iter={}'.format(counter))\n",
    "        lastQ = Q\n",
    "        EStep(data)\n",
    "        MStep(data)\n",
    "        Q = computeQ(data)\n",
    "        counter += 1\n",
    "\n",
    "def calcLogProbL(item, *args):\n",
    "    data = args[-1]\n",
    "    print(data[\"alpha\"], data[\"labels\"])\n",
    "\n",
    "    j = int(item[0])\n",
    "    delta = args[0][j]\n",
    "    noResp = args[1][j]\n",
    "    oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "    exponents = item[1:]\n",
    "\n",
    "    correct = logsigmoid(exponents[delta]).sum()\n",
    "    wrong = (logsigmoid(-exponents[oneMinusDelta]) - np.log(float(data[\"numClasses\"] - 1))).sum()\n",
    "\n",
    "    return correct + wrong\n",
    "\n",
    "def EStep(data):\n",
    "    data[\"probZ\"] = np.tile(np.log(data[\"priorZ\"]), data[\"numTasks\"]).reshape(data[\"numTasks\"], data[\"numClasses\"])\n",
    "\n",
    "    ab = np.dot(np.array([np.exp(data[\"beta\"])]).T, np.array([data[\"alpha\"]]))\n",
    "    ab = np.c_[np.arange(data[\"numTasks\"]), ab]\n",
    "    for k in range(data[\"numClasses\"]):\n",
    "        data[\"probZ\"][:, k] = np.apply_along_axis(calcLogProbL, 1, ab,\n",
    "                                               (data[\"labels\"] == k + 1),\n",
    "                                               (data[\"labels\"] == 0),\n",
    "                                               data)  # Pass data as an additional argument\n",
    "\n",
    "    data[\"probZ\"] = np.exp(data[\"probZ\"])\n",
    "    s = data[\"probZ\"].sum(axis=1)\n",
    "    data[\"probZ\"] = (data[\"probZ\"].T / s).T\n",
    "    assert not np.any(np.isnan(data[\"probZ\"])), 'Invalid Value [EStep]'\n",
    "\n",
    "\n",
    "\n",
    "def df(x, *args):\n",
    "    data = args[0]\n",
    "    d = Dataset(labels=data[\"labels\"], numLabels=data[\"numLabels\"], numLabelers=data[\"numLabelers\"],\n",
    "                numTasks=data[\"numTasks\"], numClasses=data[\"numClasses\"],\n",
    "                priorAlpha=data[\"priorAlpha\"], priorBeta=data[\"priorBeta\"],\n",
    "                priorZ=data[\"priorZ\"], probZ=data[\"probZ\"])\n",
    "    unpackX(x, d)\n",
    "    dQdAlpha, dQdBeta = gradientQ(d)\n",
    "    return np.r_[-dQdAlpha, -dQdBeta]\n",
    "\n",
    "\n",
    "def f(x, *args):\n",
    "    u\"\"\"Return the value of the objective function\n",
    "    \"\"\"\n",
    "    data = args[0]\n",
    "    d = Dataset(labels=data[\"labels\"], numLabels=data[\"numLabels\"], numLabelers=data[\"numLabelers\"],\n",
    "                numTasks=data[\"numTasks\"], numClasses=data[\"numClasses\"],\n",
    "                priorAlpha=data[\"priorAlpha\"], priorBeta=data[\"priorBeta\"],\n",
    "                priorZ=data[\"priorZ\"], probZ=data[\"probZ\"])\n",
    "    unpackX(x, d)\n",
    "    return - computeQ(d)\n",
    "\n",
    "def MStep(data):\n",
    "    initial_params = packX(data)\n",
    "    params = sp.optimize.minimize(fun=f, x0=initial_params, args=(data,), method='CG',\n",
    "                                  jac=df, tol=0.01,\n",
    "                                  options={'maxiter': 25, 'disp': verbose})\n",
    "    unpackX(params.x, data)\n",
    "\n",
    "\n",
    "def computeQ(data):\n",
    "    Q = 0\n",
    "    Q += (data[\"probZ\"] * np.log(data[\"priorZ\"])).sum()\n",
    "\n",
    "    ab = np.dot(np.array([np.exp(data[\"beta\"])]).T, np.array([data[\"alpha\"]]))\n",
    "\n",
    "    logSigma = logsigmoid(ab)\n",
    "    idxna = np.isnan(logSigma)\n",
    "    if np.any(idxna):\n",
    "        logger.warning('an invalid value was assigned to np.log [computeQ]')\n",
    "        logSigma[idxna] = ab[idxna]\n",
    "\n",
    "    logOneMinusSigma = logsigmoid(-ab) - np.log(float(data[\"numClasses\"] - 1))\n",
    "    idxna = np.isnan(logOneMinusSigma)\n",
    "    if np.any(idxna):\n",
    "        logger.warning('an invalid value was assigned to np.log [computeQ]')\n",
    "        logOneMinusSigma[idxna] = -ab[idxna]\n",
    "\n",
    "    for k in range(data[\"numClasses\"]):\n",
    "        delta = (data[\"labels\"] == k + 1)\n",
    "        Q += (data[\"probZ\"][:, k] * logSigma.T).T[delta].sum()\n",
    "        oneMinusDelta = (data[\"labels\"] != k + 1) & (data[\"labels\"] != 0)\n",
    "        Q += (data[\"probZ\"][:, k] * logOneMinusSigma.T).T[oneMinusDelta].sum()\n",
    "\n",
    "    Q += np.log(sp.stats.norm.pdf(data[\"alpha\"] - data[\"priorAlpha\"])).sum()\n",
    "    Q += np.log(sp.stats.norm.pdf(data[\"beta\"] - data[\"priorBeta\"])).sum()\n",
    "\n",
    "    if np.isnan(Q):\n",
    "        return -np.inf\n",
    "    return Q\n",
    "\n",
    "\n",
    "def gradientQ(data):\n",
    "    dQdAlpha = - (data[\"alpha\"] - data[\"priorAlpha\"])\n",
    "    dQdBeta = - (data[\"beta\"] - data[\"priorBeta\"])\n",
    "\n",
    "    ab = np.exp(data[\"beta\"])[:, np.newaxis] * data[\"alpha\"]\n",
    "    sigma = sigmoid(ab)\n",
    "    sigma[np.isnan(sigma)] = 0\n",
    "\n",
    "    for k in range(data[\"numClasses\"]):\n",
    "        delta = (data[\"labels\"] == k + 1)\n",
    "        oneMinusDelta = (data[\"labels\"] != k + 1) & (data[\"labels\"] != 0)\n",
    "\n",
    "        dQdAlpha += (data[\"probZ\"][:, k][:, np.newaxis] * np.exp(data[\"beta\"])[:, np.newaxis] * (delta - sigma)).sum(axis=0)\n",
    "        dQdBeta += (data[\"probZ\"][:, k][:, np.newaxis] * data[\"alpha\"] * (delta - sigma)).sum(axis=1)\n",
    "\n",
    "    return dQdAlpha, dQdBeta\n",
    "\n",
    "\n",
    "def dAlpha(item, *args):\n",
    "    i = int(item[0])\n",
    "    sigma_ab = item[1:]\n",
    "\n",
    "    delta = args[0][:, i]\n",
    "    noResp = args[1][:, i]\n",
    "    oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "    probZ = args[2]\n",
    "\n",
    "    data = args[3] \n",
    "\n",
    "    correct = probZ[delta] * np.exp(data[\"beta\"][delta]) * (1 - sigma_ab[delta])\n",
    "    wrong = probZ[oneMinusDelta] * np.exp(data[\"beta\"][oneMinusDelta]) * (-sigma_ab[oneMinusDelta])\n",
    "\n",
    "    return correct.sum() + wrong.sum()\n",
    "\n",
    "\n",
    "def dBeta(item, *args):\n",
    "    j = int(item[0])\n",
    "    sigma_ab = item[1:]\n",
    "\n",
    "    delta = args[0][j]\n",
    "    noResp = args[1][j]\n",
    "    oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "    probZ = args[2][j]\n",
    "    data = args[3] \n",
    "\n",
    "    correct = probZ * data[\"alpha\"][delta] * (1 - sigma_ab[delta])\n",
    "    wrong = probZ * data[\"alpha\"][oneMinusDelta] * (-sigma_ab[oneMinusDelta])\n",
    "\n",
    "    return correct.sum() + wrong.sum()\n",
    "\n",
    "\n",
    "def packX(data):\n",
    "    return np.r_[data[\"alpha\"].copy(), data[\"beta\"].copy()]\n",
    "\n",
    "\n",
    "def unpackX(x, data):\n",
    "    data[\"alpha\"] = x[:data[\"numLabelers\"]].copy()\n",
    "    data[\"beta\"] = x[data[\"numLabelers\"]:].copy()\n",
    "\n",
    "\n",
    "def output(data):\n",
    "    alpha = np.c_[np.arange(data[\"numLabelers\"]), data[\"alpha\"]]\n",
    "    beta = np.c_[np.arange(data[\"numTasks\"]), np.exp(data[\"beta\"])]\n",
    "    probZ = np.c_[np.arange(data[\"numTasks\"]), data[\"probZ\"]]\n",
    "    label = np.c_[np.arange(data[\"numTasks\"]), np.argmax(data[\"probZ\"], axis=1)]\n",
    "\n",
    "    return {\"alpha\": alpha,\n",
    "            \"beta\": beta,\n",
    "            \"probZ\": probZ,\n",
    "            \"labels\": label}\n",
    "\n",
    "\n",
    "def main():\n",
    "    global debug, verbose\n",
    "    init_logger()\n",
    "\n",
    "    debug = False\n",
    "    verbose = False\n",
    "\n",
    "    data = load_data(all_results)\n",
    "\n",
    "    EM(data)\n",
    "    r = output(data)\n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
