{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Gemini vs Ensemble for MMLU\n",
    "\n",
    "\n",
    "to do:\n",
    "\n",
    "-ignore claude, add gemma, palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import Annotate\n",
    "from config import PALM_CONFIG, GEMINI_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 420\n",
    "now = datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cais/mmlu\", \"all\")\n",
    "\n",
    "# # take a small sample for dev purposes\n",
    "dataset = dataset['test'].shuffle(seed=seed).select(range(10))\n",
    "\n",
    "# # user provided data description\n",
    "# DESCRIPTION = \"\"\"\n",
    "# This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge.\n",
    "# The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn.\n",
    "# To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability.\n",
    "# This covers 57 subjects  across STEM, the humanities, the social sciences, and more. \n",
    "# It ranges in difficulty from an elementary level to an advanced professional level, and it tests both world knowledge and problem solving ability. \n",
    "# Subjects range from traditional areas, such as mathematics and history, to more specialized areas like law and ethics.\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{datapoint}\n",
    "</QUESTION>\n",
    "------------\n",
    "\n",
    "<CHOICES>\n",
    "{labels}\n",
    "</choices>\n",
    "------------\n",
    "\n",
    "INSTRUCTION:\n",
    "- read the above question carefully.\n",
    "- you are given 4 choices seperated by comma in <CHOICES>.\n",
    "- take your time and pick the precise correct answer from <CHOICES> for the given <QUESTION>.\n",
    "- remember that there is always only one correct answer.\n",
    "- return the exact correct answer from <CHOICES>. Don't provide explanations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "prompt = [gemini_prompt_template.format(datapoint=x['question'],\n",
    "                                        labels=x['choices']) for x in dataset]\n",
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"palm\",\n",
    "    \"gemini\",\n",
    "    # \"claude\"\n",
    "    ]\n",
    "\n",
    "\n",
    "palm_1 =  copy.deepcopy(PALM_CONFIG)\n",
    "palm_1['config_name'] = \"temp_0.4\"\n",
    "palm_2 =  copy.deepcopy(PALM_CONFIG)\n",
    "palm_2['config_name'] = \"temp_0.9\"\n",
    "palm_2[\"generation_config\"]['temperature'] = 0.9\n",
    "\n",
    "\n",
    "gemini_1 =  copy.deepcopy(GEMINI_CONFIG)\n",
    "gemini_1['config_name'] = \"-1.0-pro-002\"\n",
    "gemini_2 =  copy.deepcopy(GEMINI_CONFIG)\n",
    "gemini_2['config_name'] = \"-1.5-flash-001\"\n",
    "gemini_2['\"model\"'] = \"gemini-1.5-flash-001\"\n",
    "gemini_3 =  copy.deepcopy(GEMINI_CONFIG)\n",
    "gemini_3['config_name'] = \"-1.0-ultra-001\"\n",
    "gemini_3['\"model\"'] = \"gemini-1.0-ultra-001\"\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    \"gemini\": [\n",
    "        gemini_1,\n",
    "        gemini_2,\n",
    "        gemini_3\n",
    "         ],\n",
    "    \"palm\": [\n",
    "        palm_1, \n",
    "        palm_2\n",
    "        ]\n",
    "}\n",
    "\n",
    "ann = Annotate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating tasks: 100%|██████████| 50/50 [00:00<00:00, 101067.57it/s]\n",
      "Gathering palm_temp_0.4 results: 100%|██████████| 10/10 [00:29<00:00,  2.96s/it]\n",
      "Gathering palm_temp_0.9 results: 100%|██████████| 10/10 [00:00<00:00, 44955.03it/s]\n",
      "Gathering gemini_-1.0-pro-002 results:   0%|          | 0/10 [00:00<?, ?it/s]2024-05-29 20:34:37,071/Annotate[ERROR]: gemini_-1.0-pro-002 Task 0 failed: Cannot get the response text.\n",
      "Cannot get the Candidate text.\n",
      "Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "Candidate:\n",
      "{\n",
      "  \"finish_reason\": \"OTHER\"\n",
      "}\n",
      "Response:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"finish_reason\": \"OTHER\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage_metadata\": {\n",
      "    \"prompt_token_count\": 168,\n",
      "    \"total_token_count\": 168\n",
      "  }\n",
      "}\n",
      "Gathering gemini_-1.0-pro-002 results: 100%|██████████| 10/10 [00:00<00:00, 9576.04it/s]\n",
      "Gathering gemini_-1.5-flash-001 results:   0%|          | 0/10 [00:00<?, ?it/s]2024-05-29 20:34:37,075/Annotate[ERROR]: gemini_-1.5-flash-001 Task 0 failed: Cannot get the response text.\n",
      "Cannot get the Candidate text.\n",
      "Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "Candidate:\n",
      "{\n",
      "  \"finish_reason\": \"OTHER\"\n",
      "}\n",
      "Response:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"finish_reason\": \"OTHER\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage_metadata\": {\n",
      "    \"prompt_token_count\": 168,\n",
      "    \"total_token_count\": 168\n",
      "  }\n",
      "}\n",
      "Gathering gemini_-1.5-flash-001 results: 100%|██████████| 10/10 [00:00<00:00, 7476.48it/s]\n",
      "Gathering gemini_-1.0-ultra-001 results:   0%|          | 0/10 [00:00<?, ?it/s]2024-05-29 20:34:37,079/Annotate[ERROR]: gemini_-1.0-ultra-001 Task 0 failed: Cannot get the response text.\n",
      "Cannot get the Candidate text.\n",
      "Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "Candidate:\n",
      "{\n",
      "  \"finish_reason\": \"OTHER\"\n",
      "}\n",
      "Response:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"finish_reason\": \"OTHER\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage_metadata\": {\n",
      "    \"prompt_token_count\": 168,\n",
      "    \"total_token_count\": 168\n",
      "  }\n",
      "}\n",
      "Gathering gemini_-1.0-ultra-001 results: 100%|██████████| 10/10 [00:00<00:00, 11434.85it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dict = await ann.classification(prompt, models, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'palm_temp_0.4': [' Homo erectus.',\n",
       "  ' simple',\n",
       "  ' Perform preliminary analytical procedures to identify accounts that may represent specific risks relevant to the engagement.',\n",
       "  \" 'All of these options.'\",\n",
       "  ' Deep pyro sequencing (NGS)',\n",
       "  ' ~Mmis',\n",
       "  ' Wrong, Not wrong',\n",
       "  ' posteriorly deviated fibular head',\n",
       "  ' Whitebear',\n",
       "  ' 0.42'],\n",
       " 'palm_temp_0.9': [' Homo erectus.',\n",
       "  ' simple',\n",
       "  ' \"Obtain an understanding of any specialized financial reporting frameworks and practices used in the entity\\'s industry.\"',\n",
       "  \" 'All of these options.'\",\n",
       "  '',\n",
       "  \" '~Mmis'\",\n",
       "  ' Wrong, Not wrong',\n",
       "  ' posteriorly deviated fibular head',\n",
       "  ' Whitebear',\n",
       "  ' 0.42'],\n",
       " 'gemini_-1.0-pro-002': [None,\n",
       "  \"'simple'\",\n",
       "  '\"Perform preliminary analytical procedures to identify accounts that may represent specific risks relevant to the engagement.\"',\n",
       "  '\"All of these options.\"',\n",
       "  'Deep pyro sequencing (NGS)',\n",
       "  \"'M~msi'\",\n",
       "  \"'Wrong, Not wrong'\",\n",
       "  'posteriorly deviated fibular head',\n",
       "  \"'Ebbinghaus'\",\n",
       "  \"'0.7'\"],\n",
       " 'gemini_-1.5-flash-001': [None,\n",
       "  \"'simple'\",\n",
       "  '\"Make inquiries of management concerning the entity\\'s procedures used in adjusting and closing the books of account.\"',\n",
       "  '\"All of these options.\" \\n',\n",
       "  \"'Deep pyro sequencing (NGS)'\",\n",
       "  \"'M~mis'\",\n",
       "  \"'Wrong, Not wrong'\",\n",
       "  \"'posteriorly deviated fibular head'\",\n",
       "  'Clark \\n',\n",
       "  \"'0.7'\"],\n",
       " 'gemini_-1.0-ultra-001': [None,\n",
       "  \"'compound'\",\n",
       "  '\"Perform preliminary analytical procedures to identify accounts that may represent specific risks relevant to the engagement.\"\\n',\n",
       "  '\"All of these options.\"',\n",
       "  'Deep pyro sequencing (NGS)',\n",
       "  \"'M~mis'\",\n",
       "  \"'Wrong, Not wrong'\",\n",
       "  'posteriorly deviated fibular head',\n",
       "  'Clark',\n",
       "  \"'0.42'\"]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'palm_temp_0.4': [2, 0, 1, 3, 2, 2, 1, 2, 2, 0],\n",
       " 'palm_temp_0.9': [2, 0, None, 3, None, 2, 1, 2, 2, 0],\n",
       " 'gemini_-1.0-pro-002': [None, 0, None, None, 2, 3, 1, 2, 3, 2],\n",
       " 'gemini_-1.5-flash-001': [None, 0, None, None, 2, 1, 1, 2, 0, 2],\n",
       " 'gemini_-1.0-ultra-001': [None, 1, None, None, 2, 1, 1, 2, 0, 0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = {}\n",
    "\n",
    "for k in output_dict.keys():\n",
    "    llm_response[k] = []\n",
    "    for idx, r in enumerate(output_dict[k]):\n",
    "        if r is not None:\n",
    "            stripped_r = r.strip().strip(\"'\")\n",
    "            if stripped_r in dataset['choices'][idx]:\n",
    "                llm_response[k].append(dataset['choices'][idx].index(stripped_r))\n",
    "            else:\n",
    "                # Handle case where stripped_r is not found in choices\n",
    "                llm_response[k].append(None)\n",
    "        else:\n",
    "            # Handle None values appropriately\n",
    "            llm_response[k].append(None)\n",
    "\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_none_with_random(data, n):\n",
    "    for key, lst in data.items():\n",
    "        for i, value in enumerate(lst):\n",
    "            if value is None:\n",
    "                lst[i] = random.randint(0, n - 1)\n",
    "\n",
    "\n",
    "\n",
    "def convert_dict_to_indexed_list(data_dict):\n",
    "    number_map = {key: index for index, key in enumerate(data_dict.keys())}\n",
    "    max_len = len(next(iter(data_dict.values())))\n",
    "\n",
    "    result = []\n",
    "    for index in range(max_len):\n",
    "        for key, value_list in data_dict.items():\n",
    "            value = value_list[index]\n",
    "            # Convert to 0 if not an integer\n",
    "            converted_value = 0 if not isinstance(value, int) else value \n",
    "            result.append([index, number_map[key], converted_value])\n",
    "    return result\n",
    "    \n",
    "\n",
    "def generate_task_config(response_dict, num_classes):\n",
    "\n",
    "    num_labels = sum(len(lst) for lst in response_dict.values())\n",
    "    num_tasks =  len(list(response_dict.values())[0])\n",
    "    num_labelers = len(response_dict)\n",
    "    z  = 1/num_classes\n",
    "\n",
    "\n",
    "    tc = [num_labels, num_labelers, num_tasks, num_classes]\n",
    "    tc.extend([z] * tc[-1])\n",
    "\n",
    "    return tc\n",
    "\n",
    "n_class = 4\n",
    "replace_none_with_random(llm_response, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_conf = generate_task_config(llm_response, n_class)\n",
    "llm_result_list = convert_dict_to_indexed_list(llm_response)\n",
    "llm_result_list.insert(0, task_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 5, 10, 4, 0.25, 0.25, 0.25, 0.25]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/llm_response__20240529.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"./data/llm_response__{now}.txt\"\n",
    "\n",
    "with open(filename, \"w\") as file:\n",
    "    for sublist in llm_result_list:\n",
    "        line = \" \".join(str(num) for num in sublist)  # Convert to string, join with spaces\n",
    "        file.write(line + \"\\n\")  # Write line and add newline\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import glad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./data/llm_response__20240529.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glad_output = glad(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'beta', 'probZ', 'labels'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glad_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 0, 2: 0, 3: 3, 4: 2, 5: 2, 6: 1, 7: 2, 8: 2, 9: 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glad_output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
