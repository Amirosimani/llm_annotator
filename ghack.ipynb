{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Gemini vs Ensemble for MMLU\n",
    "\n",
    "\n",
    "to do:\n",
    "\n",
    "-ignore claude, add gemma, palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =42\n",
    "now = datetime.now().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cais/mmlu\", \"all\")\n",
    "\n",
    "# # take a small sample for dev purposes\n",
    "dataset = dataset['test'].shuffle(seed=seed).select(range(20))\n",
    "\n",
    "# user provided data description\n",
    "DESCRIPTION = \"\"\"\n",
    "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge.\n",
    "The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn.\n",
    "To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability.\n",
    "This covers 57 subjects  across STEM, the humanities, the social sciences, and more. \n",
    "It ranges in difficulty from an elementary level to an advanced professional level, and it tests both world knowledge and problem solving ability. \n",
    "Subjects range from traditional areas, such as mathematics and history, to more specialized areas like law and ethics.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_prompt_template = \"\"\"\n",
    "<QUESTION>\n",
    "{datapoint}\n",
    "</QUESTION>\n",
    "------------\n",
    "\n",
    "<CHOICES>\n",
    "{labels}\n",
    "</choices>\n",
    "------------\n",
    "\n",
    "INSTRUCTION:\n",
    "- read the above question carefully.\n",
    "- you are given 4 choices seperated by comma in <CHOICES>.\n",
    "- take your time and pick the precise correct answer from <CHOICES> for the given <QUESTION>.\n",
    "- remember that there is always only one correct answer.\n",
    "- return the exact correct answer from <CHOICES>. Don't provide explanations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [gemini_prompt_template.format(description= DESCRIPTION,\n",
    "                                        datapoint=x['question'],\n",
    "                                        labels=x['choices']) for x in dataset]\n",
    "print(len(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # \"palm\",\n",
    "    # \"gemini\",\n",
    "    \"claude\"\n",
    "    ]\n",
    "\n",
    "ann = Annotate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await ann.classification(prompt, models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [dataset['choices'][idx][v] for idx, v in enumerate(dataset['answer'])]\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug GLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD = 1e-5\n",
    "\n",
    "verbose = False\n",
    "debug = False\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = [20000, 20, 1000, 2, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/output/annotation_output__20240515.json', 'r') as file:\n",
    "    ddddd = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, labels=None,\n",
    "                 numLabels=-1, numLabelers=-1, numTasks=-1, numClasses=-1,\n",
    "                 priorAlpha=None, priorBeta=None, priorZ=None,\n",
    "                 alpha=None, beta=None, probZ=None):\n",
    "        self.labels = labels\n",
    "        self.numLabels = numLabels\n",
    "        self.numLabelers = numLabelers\n",
    "        self.numTasks = numTasks\n",
    "        self.numClasses = numClasses\n",
    "        self.priorAlpha = priorAlpha\n",
    "        self.priorBeta = priorBeta\n",
    "        self.priorZ = priorZ\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.probZ = probZ\n",
    "\n",
    "def convert_dict_to_indexed_list(data_dict):\n",
    "    number_map = {key: index for index, key in enumerate(data_dict.keys())}\n",
    "    max_len = len(next(iter(data_dict.values())))\n",
    "\n",
    "    result = []\n",
    "    for index in range(max_len):\n",
    "        for key, value_list in data_dict.items():\n",
    "            value = value_list[index]\n",
    "            # Convert to 0 if not an integer\n",
    "            converted_value = 0 if not isinstance(value, int) else value \n",
    "            result.append([index, number_map[key], converted_value])\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(sample_data, task_config):\n",
    "    data = Dataset()\n",
    "\n",
    "    result = convert_dict_to_indexed_list(sample_data)\n",
    "\n",
    "     # Read parameters\n",
    "    data.numLabels = task_config[0]\n",
    "    data.numLabelers = task_config[1]\n",
    "    data.numTasks = task_config[2]\n",
    "    data.numClasses = task_config[3]\n",
    "    data.priorZ = np.array([float(x) for x in task_config[4:]])\n",
    "    assert len(data.priorZ) == data.numClasses, 'Incorrect input header'\n",
    "    assert data.priorZ.sum() == 1, 'Incorrect priorZ given'\n",
    "    if verbose:\n",
    "        logger.info('Reading {} labels of {} labelers over {} tasks for prior P(Z) = {}'.format(data.numLabels,\n",
    "                                                                                                data.numLabelers,\n",
    "                                                                                                data.numTasks,\n",
    "                                                                                                data.priorZ))\n",
    "    # Read Labels\n",
    "    data.labels = np.zeros((data.numTasks, data.numLabelers))\n",
    "    for line in result:\n",
    "        task, labeler, label = map(int, line)\n",
    "        if debug:\n",
    "            logger.info(\"Read: task({})={} by labeler {}\".format(task, label, labeler))\n",
    "        data.labels[task][labeler] = label + 1\n",
    "    # Initialize Probs\n",
    "    data.priorAlpha = np.ones(data.numLabelers)\n",
    "    data.priorBeta = np.ones(data.numTasks)\n",
    "    data.probZ = np.empty((data.numTasks, data.numClasses))\n",
    "    # data.priorZ = (np.zeros((data.numClasses, data.numTasks)).T + data.priorZ).T\n",
    "    data.beta = np.empty(data.numTasks)\n",
    "    data.alpha = np.empty(data.numLabelers)\n",
    "\n",
    "    return data\n",
    "\n",
    "def init_logger():\n",
    "    global logger\n",
    "    logger = logging.getLogger('GLAD')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    log_fmt = '%(asctime)s/%(name)s[%(levelname)s]: %(message)s'\n",
    "    logging.basicConfig(format=log_fmt)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "def logsigmoid(x):\n",
    "    return - np.log(1 + np.exp(-x))\n",
    "\n",
    "def EM(data):\n",
    "    u\"\"\"Infer true labels, tasks' difficulty and workers' ability\n",
    "    \"\"\"\n",
    "    # Initialize parameters to starting values\n",
    "    data.alpha = data.priorAlpha.copy()\n",
    "    data.beta = data.priorBeta.copy()\n",
    "    data.probZ[:] = data.priorZ[:]\n",
    "\n",
    "    EStep(data)\n",
    "    lastQ = computeQ(data)\n",
    "    MStep(data)\n",
    "    Q = computeQ(data)\n",
    "    counter = 1\n",
    "    while abs((Q - lastQ) / lastQ) > THRESHOLD:\n",
    "        if verbose: logger.info('EM: iter={}'.format(counter))\n",
    "        lastQ = Q\n",
    "        EStep(data)\n",
    "        MStep(data)\n",
    "        Q = computeQ(data)\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "def EStep(data):\n",
    "    u\"\"\"Evaluate the posterior probability of true labels given observed labels and parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def calcLogProbL(item, *args):\n",
    "        j = int(item[0])  # task ID\n",
    "\n",
    "        # List[boolean]: denotes if the worker i picked the focused class for the task j\n",
    "        ## formally, delta[i, j] = True if l_ij == z_j for i = 0, ..., m-1 (m=# of workers)\n",
    "        delta = args[0][j]\n",
    "        noResp = args[1][j]\n",
    "        oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "        # List[float]: alpha_i * exp(beta_j) for i = 0, ..., m-1\n",
    "        exponents = item[1:]\n",
    "\n",
    "        # Log likelihood for the observations s.t. l_ij == z_j\n",
    "        correct = logsigmoid(exponents[delta]).sum()\n",
    "        # Log likelihood for the observations s.t. l_ij != z_j\n",
    "        wrong = (logsigmoid(-exponents[oneMinusDelta]) - np.log(float(data.numClasses - 1))).sum()\n",
    "\n",
    "        # Return log likelihood\n",
    "        return correct + wrong\n",
    "\n",
    "    if verbose: logger.info('EStep')\n",
    "    data.probZ = np.tile(np.log(data.priorZ), data.numTasks).reshape(data.numTasks, data.numClasses)\n",
    "\n",
    "    ab = np.dot(np.array([np.exp(data.beta)]).T, np.array([data.alpha]))\n",
    "    ab = np.c_[np.arange(data.numTasks), ab]\n",
    "\n",
    "    for k in range(data.numClasses):\n",
    "        data.probZ[:, k] = np.apply_along_axis(calcLogProbL, 1, ab,\n",
    "                                               (data.labels == k + 1),\n",
    "                                               (data.labels == 0))\n",
    "\n",
    "    # Exponentiate and renormalize\n",
    "    data.probZ = np.exp(data.probZ)\n",
    "    s = data.probZ.sum(axis=1)\n",
    "    data.probZ = (data.probZ.T / s).T\n",
    "    assert not np.any(np.isnan(data.probZ)), 'Invalid Value [EStep]'\n",
    "    assert not np.any(np.isinf(data.probZ)), 'Invalid Value [EStep]'\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def packX(data):\n",
    "    return np.r_[data.alpha.copy(), data.beta.copy()]\n",
    "\n",
    "\n",
    "def unpackX(x, data):\n",
    "    data.alpha = x[:data.numLabelers].copy()\n",
    "    data.beta = x[data.numLabelers:].copy()\n",
    "\n",
    "\n",
    "def getBoundsX(data, alpha=(-100, 100), beta=(-100, 100)):\n",
    "    alpha_bounds = np.array([[alpha[0], alpha[1]] for i in range(data.numLabelers)])\n",
    "    beta_bounds = np.array([[beta[0], beta[1]] for i in range(data.numLabelers)])\n",
    "    return np.r_[alpha_bounds, beta_bounds]\n",
    "\n",
    "\n",
    "def f(x, *args):\n",
    "    u\"\"\"Return the value of the objective function\n",
    "    \"\"\"\n",
    "    data = args[0]\n",
    "    d = Dataset(labels=data.labels, numLabels=data.numLabels, numLabelers=data.numLabelers,\n",
    "                numTasks=data.numTasks, numClasses=data.numClasses,\n",
    "                priorAlpha=data.priorAlpha, priorBeta=data.priorBeta,\n",
    "                priorZ=data.priorZ, probZ=data.probZ)\n",
    "    unpackX(x, d)\n",
    "    return - computeQ(d)\n",
    "\n",
    "\n",
    "def df(x, *args):\n",
    "    u\"\"\"Return gradient vector\n",
    "    \"\"\"\n",
    "    data = args[0]\n",
    "    d = Dataset(labels=data.labels, numLabels=data.numLabels, numLabelers=data.numLabelers,\n",
    "                numTasks=data.numTasks, numClasses=data.numClasses,\n",
    "                priorAlpha=data.priorAlpha, priorBeta=data.priorBeta,\n",
    "                priorZ=data.priorZ, probZ=data.probZ)\n",
    "    unpackX(x, d)\n",
    "    dQdAlpha, dQdBeta = gradientQ(d)\n",
    "    # Flip the sign since we want to minimize\n",
    "    assert not np.any(np.isinf(dQdAlpha)), 'Invalid Gradient Value [Alpha]'\n",
    "    assert not np.any(np.isinf(dQdBeta)), 'Invalid Gradient Value [Beta]'\n",
    "    assert not np.any(np.isnan(dQdAlpha)), 'Invalid Gradient Value [Alpha]'\n",
    "    assert not np.any(np.isnan(dQdBeta)), 'Invalid Gradient Value [Beta]'\n",
    "    return np.r_[-dQdAlpha, -dQdBeta]\n",
    "\n",
    "\n",
    "def MStep(data):\n",
    "    if verbose: logger.info('MStep')\n",
    "    initial_params = packX(data)\n",
    "    params = sp.optimize.minimize(fun=f, x0=initial_params, args=(data,), method='CG',\n",
    "                                  jac=df, tol=0.01,\n",
    "                                  options={'maxiter': 25, 'disp': verbose})\n",
    "    if debug:\n",
    "        logger.debug(params)\n",
    "    unpackX(params.x, data)\n",
    "\n",
    "\n",
    "def computeQ(data):\n",
    "    u\"\"\"Calculate the expectation of the joint likelihood\n",
    "    \"\"\"\n",
    "    Q = 0\n",
    "    # Start with the expectation of the sum of priors over all tasks\n",
    "    Q += (data.probZ * np.log(data.priorZ)).sum()\n",
    "\n",
    "    # the expectation of the sum of posteriors over all tasks\n",
    "    ab = np.dot(np.array([np.exp(data.beta)]).T, np.array([data.alpha]))\n",
    "\n",
    "    # logSigma = - np.log(1 + np.exp(-ab))\n",
    "    logSigma = logsigmoid(ab)  # logP\n",
    "    idxna = np.isnan(logSigma)\n",
    "    if np.any(idxna):\n",
    "        logger.warning('an invalid value was assigned to np.log [computeQ]')\n",
    "        logSigma[idxna] = ab[idxna]  # For large negative x, -log(1 + exp(-x)) = x\n",
    "\n",
    "    # logOneMinusSigma = - np.log(1 + np.exp(ab))\n",
    "    logOneMinusSigma = logsigmoid(-ab) - np.log(float(data.numClasses - 1))  # log((1-P)/(K-1))\n",
    "    idxna = np.isnan(logOneMinusSigma)\n",
    "    if np.any(idxna):\n",
    "        logger.warning('an invalid value was assigned to np.log [computeQ]')\n",
    "        logOneMinusSigma[idxna] = -ab[idxna]  # For large positive x, -log(1 + exp(x)) = x\n",
    "\n",
    "    for k in range(data.numClasses):\n",
    "        delta = (data.labels == k + 1)\n",
    "        Q += (data.probZ[:, k] * logSigma.T).T[delta].sum()\n",
    "        oneMinusDelta = (data.labels != k + 1) & (data.labels != 0)  # label == 0 -> no response\n",
    "        Q += (data.probZ[:, k] * logOneMinusSigma.T).T[oneMinusDelta].sum()\n",
    "\n",
    "    # Add Gaussian (standard normal) prior for alpha\n",
    "    Q += np.log(sp.stats.norm.pdf(data.alpha - data.priorAlpha)).sum()\n",
    "\n",
    "    # Add Gaussian (standard normal) prior for beta\n",
    "    Q += np.log(sp.stats.norm.pdf(data.beta - data.priorBeta)).sum()\n",
    "\n",
    "    if debug:\n",
    "        logger.debug('a[0]={} a[1]={} a[2]={} b[0]={}'.format(data.alpha[0], data.alpha[1],\n",
    "                                                              data.alpha[2], data.beta[0]))\n",
    "        logger.debug('Q={}'.format(Q))\n",
    "    if np.isnan(Q):\n",
    "        return -np.inf\n",
    "    return Q\n",
    "\n",
    "\n",
    "def gradientQ(data):\n",
    "    def dAlpha(item, *args):\n",
    "        i = int(item[0])  # worker ID\n",
    "        sigma_ab = item[1:] # List[float], dim=(n,): sigmoid(alpha_i * beta_j) for j = 0, ..., n-1\n",
    "\n",
    "        # List[boolean], dim=(n,): denotes if the worker i picked the focused class for\n",
    "        # task j (j=0, ..., n-1)\n",
    "        delta = args[0][:, i]\n",
    "        noResp = args[1][:, i]\n",
    "        oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "        # List[float], dim=(n,): Prob of the true label of the task j being the focused class (p^k)\n",
    "        probZ = args[2]\n",
    "\n",
    "        correct = probZ[delta] * np.exp(data.beta[delta]) * (1 - sigma_ab[delta])\n",
    "        wrong = probZ[oneMinusDelta] * np.exp(data.beta[oneMinusDelta]) * (-sigma_ab[oneMinusDelta])\n",
    "        # Note: The derivative in Whitehill et al.'s appendix has the term ln(K-1), which is incorrect.\n",
    "\n",
    "        return correct.sum() + wrong.sum()\n",
    "\n",
    "    def dBeta(item, *args):\n",
    "        j = int(item[0])  # task ID\n",
    "        sigma_ab = item[1:] # List[float], dim=(m,): sigmoid(alpha_i * beta_j) for i = 0, ..., m-1\n",
    "\n",
    "        # List[boolean], dim=(m,): denotes if the worker i picked the focused class for\n",
    "        # task j (i=0, ..., m-1)\n",
    "        delta = args[0][j]\n",
    "        noResp = args[1][j]\n",
    "        oneMinusDelta = (~delta) & (~noResp)\n",
    "\n",
    "        # float: Prob of the true label of the task j being the focused class (p^k)\n",
    "        probZ = args[2][j]\n",
    "\n",
    "        correct = probZ * data.alpha[delta] * (1 - sigma_ab[delta])\n",
    "        wrong = probZ * data.alpha[oneMinusDelta] * (-sigma_ab[oneMinusDelta])\n",
    "\n",
    "        return correct.sum() + wrong.sum()\n",
    "\n",
    "    # prior prob.\n",
    "    dQdAlpha = - (data.alpha - data.priorAlpha)\n",
    "    dQdBeta = - (data.beta - data.priorBeta)\n",
    "\n",
    "    ab = np.dot(np.array([np.exp(data.beta)]).T, np.array([data.alpha]))\n",
    "\n",
    "    sigma = sigmoid(ab)\n",
    "    sigma[np.isnan(sigma)] = 0  # :TODO check if this is correct\n",
    "\n",
    "    labelersIdx = np.arange(data.numLabelers).reshape((1, data.numLabelers))\n",
    "    sigma = np.r_[labelersIdx, sigma]\n",
    "    sigma = np.c_[np.arange(-1, data.numTasks), sigma]\n",
    "    # sigma: List[List[float]]: dim=(n+1, m+1) where n = # of tasks and m = # of workers\n",
    "    # sigma[0] = List[float]: worker IDs (-1, 0, ..., m-1) where the first -1 is a pad\n",
    "    # sigma[:, 0] = List[float]: task IDs (-1, 0, ..., n-1) where the first -1 is a pad\n",
    "\n",
    "    for k in range(data.numClasses):\n",
    "        dQdAlpha += np.apply_along_axis(dAlpha, 0, sigma[:, 1:],\n",
    "                                        (data.labels == k + 1),\n",
    "                                        (data.labels == 0),\n",
    "                                        data.probZ[:, k])\n",
    "\n",
    "        dQdBeta += np.apply_along_axis(dBeta, 1, sigma[1:],\n",
    "                                       (data.labels == k + 1),\n",
    "                                        (data.labels == 0),\n",
    "                                       data.probZ[:, k]) * np.exp(data.beta)\n",
    "\n",
    "    if debug:\n",
    "        logger.debug('dQdAlpha[0]={} dQdAlpha[1]={} dQdAlpha[2]={} dQdBeta[0]={}'.format(dQdAlpha[0], dQdAlpha[1],\n",
    "                                                                                         dQdAlpha[2], dQdBeta[0]))\n",
    "    return dQdAlpha, dQdBeta\n",
    "\n",
    "\n",
    "def output(data):\n",
    "    alpha = np.c_[np.arange(data.numLabelers), data.alpha]\n",
    "    np.savetxt('data/alpha.csv', alpha, fmt=['%d', '%.5f'], delimiter=',', header='id,alpha')\n",
    "    beta = np.c_[np.arange(data.numTasks), np.exp(data.beta)]\n",
    "    np.savetxt('data/beta.csv', beta, fmt=['%d', '%.5f'], delimiter=',', header='id,beta')\n",
    "    probZ = np.c_[np.arange(data.numTasks), data.probZ]\n",
    "    np.savetxt(fname='data/probZ.csv',\n",
    "               X=probZ,\n",
    "               fmt=['%d'] + (['%.5f'] * data.numClasses),\n",
    "               delimiter=',',\n",
    "               header='id,' + ','.join(['z' + str(k) for k in range(data.numClasses)]))\n",
    "    label = np.c_[np.arange(data.numTasks), np.argmax(data.probZ, axis=1)]\n",
    "    np.savetxt('data/label_glad.csv', label, fmt=['%d', '%d'], delimiter=',', header='id,label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, task_config):\n",
    "    data = load_data(data, task_config)\n",
    "    EM(data)\n",
    "\n",
    "    output(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
